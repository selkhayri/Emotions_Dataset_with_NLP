{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy\n",
    "from tensorflow.sparse import  SparseTensor, to_dense\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the size of the columns to be able to view more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display column width to 500\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplace i will know that it is still on the property</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  \\\n",
       "0                                                                                       i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake   \n",
       "2                                                              im grabbing a minute to post i feel greedy wrong   \n",
       "3                  i am ever feeling nostalgic about the fireplace i will know that it is still on the property   \n",
       "4                                                                                          i am feeling grouchy   \n",
       "\n",
       "     label  \n",
       "0  sadness  \n",
       "1  sadness  \n",
       "2    anger  \n",
       "3     love  \n",
       "4    anger  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv files\n",
    "\n",
    "data_train = pd.read_csv(\"train.txt\", sep=';', header=None)\n",
    "data_val = pd.read_csv(\"val.txt\", sep=';', header=None)\n",
    "data_test = pd.read_csv(\"test.txt\", sep=';', header=None)\n",
    "\n",
    "# Set the column headers of the dataframes\n",
    "\n",
    "data_train.columns = ['text', 'label']\n",
    "data_val.columns = ['text', 'label']\n",
    "data_test.columns = ['text', 'label']\n",
    "\n",
    "# Combine all three dataframes into one\n",
    "\n",
    "data = pd.concat((data_train,data_val,data_test),axis=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20000\n",
       "Name: punct_count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a punct_count column to contain the number of punctuation characters in each line of data\n",
    "data[\"punct_count\"] = len([char for char in data[\"text\"] if char in string.punctuation])\n",
    "\n",
    "### Get the frequency of the number of punctuation counts \n",
    "data[\"punct_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Additional Stop words\n",
    "data['text_tokenized'] = data[\"text\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, didnt, feel, humiliated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, can, go, from, feeling, so, hopeless, to, so, damned, hopeful, just, from, being, around, someone, who, cares, and, is, awake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, grabbing, a, minute, to, post, i, feel, greedy, wrong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplace i will know that it is still on the property</td>\n",
       "      <td>love</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, am, ever, feeling, nostalgic, about, the, fireplace, i, will, know, that, it, is, still, on, the, property]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, am, feeling, grouchy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  \\\n",
       "0                                                                                       i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake   \n",
       "2                                                              im grabbing a minute to post i feel greedy wrong   \n",
       "3                  i am ever feeling nostalgic about the fireplace i will know that it is still on the property   \n",
       "4                                                                                          i am feeling grouchy   \n",
       "\n",
       "     label  punct_count  \\\n",
       "0  sadness            0   \n",
       "1  sadness            0   \n",
       "2    anger            0   \n",
       "3     love            0   \n",
       "4    anger            0   \n",
       "\n",
       "                                                                                                                       text_tokenized  \n",
       "0                                                                                                        [i, didnt, feel, humiliated]  \n",
       "1  [i, can, go, from, feeling, so, hopeless, to, so, damned, hopeful, just, from, being, around, someone, who, cares, and, is, awake]  \n",
       "2                                                                         [im, grabbing, a, minute, to, post, i, feel, greedy, wrong]  \n",
       "3                     [i, am, ever, feeling, nostalgic, about, the, fireplace, i, will, know, that, it, is, still, on, the, property]  \n",
       "4                                                                                                           [i, am, feeling, grouchy]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         6761\n",
       "sadness     5797\n",
       "anger       2709\n",
       "fear        2373\n",
       "love        1641\n",
       "surprise     719\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Additional Stop words\n",
    "stop_words = [\"arent\", \"cant\", \"couldnt\", \"didnt\", \"doesnt\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"hed\", \"hell\", \"hes\", \"Id\", \"Ill\", \"Im\", \"Ive\", \"isnt\", \"lets\", \"mightnt\", \"mustnt\", \"shant\", \"shed\", \"shell\", \"shes\", \"shouldnt\", \"thats\", \"theres\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"wed\", \"were\", \"weve\", \"werent\", \"whatll\", \"whatre\", \"whats\", \"whatve\", \"wheres\", \"whos\", \"wholl\", \"whore\", \"whos\", \"whove\", \"wont\", \"wouldnt\", \"youd\", \"youll\", \"youre\", \"youve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>punct_count</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, didnt, feel, humiliated]</td>\n",
       "      <td>feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, can, go, from, feeling, so, hopeless, to, so, damned, hopeful, just, from, being, around, someone, who, cares, and, is, awake]</td>\n",
       "      <td>go feeling hopeless damned hopeful around someone care awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, grabbing, a, minute, to, post, i, feel, greedy, wrong]</td>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplace i will know that it is still on the property</td>\n",
       "      <td>love</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, am, ever, feeling, nostalgic, about, the, fireplace, i, will, know, that, it, is, still, on, the, property]</td>\n",
       "      <td>ever feeling nostalgic fireplace know still property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, am, feeling, grouchy]</td>\n",
       "      <td>feeling grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  \\\n",
       "0                                                                                       i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake   \n",
       "2                                                              im grabbing a minute to post i feel greedy wrong   \n",
       "3                  i am ever feeling nostalgic about the fireplace i will know that it is still on the property   \n",
       "4                                                                                          i am feeling grouchy   \n",
       "\n",
       "     label  punct_count  \\\n",
       "0  sadness            0   \n",
       "1  sadness            0   \n",
       "2    anger            0   \n",
       "3     love            0   \n",
       "4    anger            0   \n",
       "\n",
       "                                                                                                                       text_tokenized  \\\n",
       "0                                                                                                        [i, didnt, feel, humiliated]   \n",
       "1  [i, can, go, from, feeling, so, hopeless, to, so, damned, hopeful, just, from, being, around, someone, who, cares, and, is, awake]   \n",
       "2                                                                         [im, grabbing, a, minute, to, post, i, feel, greedy, wrong]   \n",
       "3                     [i, am, ever, feeling, nostalgic, about, the, fireplace, i, will, know, that, it, is, still, on, the, property]   \n",
       "4                                                                                                           [i, am, feeling, grouchy]   \n",
       "\n",
       "                                          text_tokenized_nostop  \n",
       "0                                               feel humiliated  \n",
       "1  go feeling hopeless damned hopeful around someone care awake  \n",
       "2                     im grabbing minute post feel greedy wrong  \n",
       "3          ever feeling nostalgic fireplace know still property  \n",
       "4                                               feeling grouchy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(word_list):\n",
    "    return \" \".join([WordNetLemmatizer().lemmatize(word) for word in word_list if word not in stopwords and word not in stop_words])\n",
    "\n",
    "data[\"text_tokenized_nostop\"] = data[\"text_tokenized\"].apply(lambda x: remove_stopwords(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15037</th>\n",
       "      <th>15038</th>\n",
       "      <th>15039</th>\n",
       "      <th>15040</th>\n",
       "      <th>15041</th>\n",
       "      <th>15042</th>\n",
       "      <th>15043</th>\n",
       "      <th>15044</th>\n",
       "      <th>15045</th>\n",
       "      <th>15046</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   15037  15038  15039  15040  15041  15042  15043  15044  15045  15046  \n",
       "0      0      0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 15047 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_count_vect = count_vect.fit_transform(data.iloc[:data.shape[0],:][\"text_tokenized_nostop\"])\n",
    "\n",
    "X_features = pd.DataFrame(X_count_vect.toarray())\n",
    "X_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the features dataframe, X_features, to a numpy array and store the result in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_features.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels column into 6 one-hot-encoded columns, one column for each of the available labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5\n",
       "0      0.0  0.0  0.0  0.0  1.0  0.0\n",
       "1      0.0  0.0  0.0  0.0  1.0  0.0\n",
       "2      1.0  0.0  0.0  0.0  0.0  0.0\n",
       "3      0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4      1.0  0.0  0.0  0.0  0.0  0.0\n",
       "...    ...  ...  ...  ...  ...  ...\n",
       "19995  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "19996  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "19997  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "19998  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "19999  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(data[[\"label\"]])\n",
    "pd.DataFrame(y.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sparse matrix to SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the training, validation, and test datasets from the larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train = X[:data_train.shape[0],:]\n",
    "y_train = y[:data_train.shape[0]]\n",
    "\n",
    "# Validation\n",
    "X_val = X[data_train.shape[0]:data_train.shape[0] + data_val.shape[0],:]\n",
    "y_val = y[data_train.shape[0]:data_train.shape[0] + data_val.shape[0]]\n",
    "\n",
    "# Test\n",
    "X_test = X[data_train.shape[0] + data_val.shape[0]:data_train.shape[0]\n",
    "              + data_val.shape[0] \n",
    "              + data_test.shape[0],:]\n",
    "y_test = y[data_train.shape[0] + data_val.shape[0]:data_train.shape[0]\n",
    "              + data_val.shape[0] \n",
    "              + data_test.shape[0]:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target dataframes to dense tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_dense(convert_sparse_matrix_to_sparse_tensor(y_train))\n",
    "y_val = to_dense(convert_sparse_matrix_to_sparse_tensor(y_val))\n",
    "y_test = to_dense(convert_sparse_matrix_to_sparse_tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "seq.add(Dense(units=1000,activation=\"relu\",input_dim=X_train.shape[1]))\n",
    "seq.add(Dropout(0.2))\n",
    "seq.add(Dense(units=50,activation=\"relu\"))\n",
    "seq.add(Dropout(0.2))\n",
    "seq.add(Dense(units=6,activation=\"softmax\"))\n",
    "\n",
    "seq.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the sequential model to the training, validating with the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.6952 - accuracy: 0.7611 - val_loss: 0.3119 - val_accuracy: 0.8925\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.2180 - accuracy: 0.9262 - val_loss: 0.2964 - val_accuracy: 0.8995\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.1548 - accuracy: 0.9509 - val_loss: 0.3257 - val_accuracy: 0.9035\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.1203 - accuracy: 0.9607 - val_loss: 0.3850 - val_accuracy: 0.9035\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.0954 - accuracy: 0.9678 - val_loss: 0.4479 - val_accuracy: 0.9040\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 66s 131ms/step - loss: 0.0831 - accuracy: 0.9737 - val_loss: 0.4606 - val_accuracy: 0.9030\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0704 - accuracy: 0.9792 - val_loss: 0.4826 - val_accuracy: 0.9015\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 0.5973 - val_accuracy: 0.8970\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.5955 - val_accuracy: 0.8990\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0470 - accuracy: 0.9863 - val_loss: 0.7205 - val_accuracy: 0.8990\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0413 - accuracy: 0.9881 - val_loss: 0.7683 - val_accuracy: 0.8995\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.7653 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.8294 - val_accuracy: 0.8995\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.8072 - val_accuracy: 0.8945\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.8974 - val_accuracy: 0.8960\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0293 - accuracy: 0.9924 - val_loss: 0.9465 - val_accuracy: 0.9005\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 1.0548 - val_accuracy: 0.9020\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0269 - accuracy: 0.9936 - val_loss: 1.0683 - val_accuracy: 0.9040\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 1.0443 - val_accuracy: 0.8980\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 1.0707 - val_accuracy: 0.8975\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "fit_model = seq.fit(X_train,y_train,epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1502"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the labels of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = seq.predict(X_test,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the test portion of the larger dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nparray = y[data_train.shape[0] + data_val.shape[0]:data_train.shape[0]\n",
    "              + data_val.shape[0] \n",
    "              + data_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert lists of floats into lists of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_int(fl):\n",
    "    int_2d = []\n",
    "    for row in fl:\n",
    "        i_row = []\n",
    "        for x in row:\n",
    "            i_row.append(int(x+0.5))\n",
    "        int_2d.append(i_row)\n",
    "    \n",
    "    return np.array(int_2d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the raw predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.46451090e-10, 3.10430891e-12, 2.16507487e-08, 2.28953079e-10,\n",
       "        1.00000000e+00, 1.79888283e-15],\n",
       "       [7.41598069e-06, 1.78853938e-07, 1.22544825e-05, 4.23727755e-08,\n",
       "        9.99980092e-01, 1.05738795e-09],\n",
       "       [1.73220997e-12, 8.53572550e-15, 6.61328603e-10, 6.05693948e-15,\n",
       "        1.00000000e+00, 1.12153552e-18],\n",
       "       ...,\n",
       "       [1.51227891e-12, 6.05553639e-13, 1.00000000e+00, 5.27890620e-08,\n",
       "        2.29030038e-13, 4.66550237e-15],\n",
       "       [3.00674552e-09, 6.46842538e-14, 9.99924064e-01, 7.58912211e-05,\n",
       "        1.07362907e-09, 4.84394859e-12],\n",
       "       [2.94989554e-11, 5.57748042e-02, 2.32384441e-08, 5.04289277e-09,\n",
       "        3.70280624e-08, 9.44225192e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the elements of the prediction dataframe to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = float_to_int(y_test_pred)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the accuracy of the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654166666666667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_pred == y_test_nparray).sum()/(y_test_pred.shape[0] * y_test_pred.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}